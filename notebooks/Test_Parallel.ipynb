{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Host capri Davide\n",
    "\n",
    "    Hostname capri.dei.unipd.it\n",
    "    User p1026u27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from append_dir import append_dirname\n",
    "append_dirname('ExIFFI')\n",
    "from utils.utils import partition_data\n",
    "from utils.feature_selection import *\n",
    "#from plot import *\n",
    "#from simulation_setup import *\n",
    "from models import *\n",
    "from models.Extended_IF import *\n",
    "from models.Extended_DIFFI_parallel import *\n",
    "from models.Extended_DIFFI_original import *\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "import os\n",
    "import pickle \n",
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = os.path.dirname(path)\n",
    "path_real = os.path.join(path, \"data\", \"real\")\n",
    "mat_files_real = glob(os.path.join(path_real, \"*.mat\"))\n",
    "mat_file_names_real = {os.path.basename(x).split(\".\")[0]: x for x in mat_files_real}\n",
    "csv_files_real = glob(os.path.join(path_real, \"*.csv\"))\n",
    "csv_file_names_real = {os.path.basename(x).split(\".\")[0]: x for x in csv_files_real}\n",
    "dataset_names = list(mat_file_names_real.keys()) + list(csv_file_names_real.keys())\n",
    "mat_file_names_real.update(csv_file_names_real)\n",
    "dataset_paths = mat_file_names_real.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicates from the loaded dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(X, y):\n",
    "    S = np.c_[X, y]\n",
    "    S = pd.DataFrame(S).drop_duplicates().to_numpy()\n",
    "    X, y = S[:, :-1], S[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset coming from a `.mat` file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = loadmat(path)\n",
    "    X, y = data[\"X\"], data[\"y\"]\n",
    "    y = np.hstack(y)\n",
    "    X, y = drop_duplicates(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset coming from a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_csv(path):\n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    if \"Unnamed: 0\" in data.columns:\n",
    "        data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    X = data[data.columns[data.columns != \"Target\"]]\n",
    "    y = data[\"Target\"]\n",
    "\n",
    "    X, y = drop_duplicates(X, y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data (with `load_data` or with `load_data_csv`), scale the data and split it into train and test set obtaining `X_train`, `X_test` that will be passed to `compute_imps`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(path):\n",
    "    extension = os.path.splitext(path)[1]\n",
    "\n",
    "    if extension == \".csv\":\n",
    "        X, y = load_data_csv(path)\n",
    "    elif extension == \".mat\":\n",
    "        X, y = load_data(path)\n",
    "    else:\n",
    "        raise ValueError(\"Extension not supported\")\n",
    "\n",
    "    X_train, X_test = partition_data(X, y)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test = np.r_[X_train, X_test]\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Global Importance of a given dataset `n_runs` times. At the end a matrix with shape `(n_runs, n_features)` is returned. Each row contains the global importance of the features for a given run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_imps(model, X_train, X_test, n_runs):\n",
    "\n",
    "    X_test=np.r_[X_train,X_test]\n",
    "\n",
    "    imps = np.zeros(shape=(n_runs, X_train.shape[1]))\n",
    "    for i in tqdm(range(n_runs)):\n",
    "        model.fit(X_train)\n",
    "        imps[i, :] = model.Global_importance(\n",
    "            X_test, calculate=True, overwrite=False, depth_based=False\n",
    "        )\n",
    "\n",
    "    return imps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `test_exiffi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function called in the `main` of `test_parallel.py` used to do the experiments on the CAPRI HPC server. For a given set of datasets it computes the global importance `n_runs` times using `Extended_DIFFI_parallel` or `Extended_DIFFI_original`and saves the importances matrices, the time stats obtained and the test arguments in a `.npz` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `test_exiffi` Parameters\n",
    "\n",
    "- `X_train`: the train set\n",
    "- `X_test`: the test set\n",
    "- `savedir`: directory where to save the results in `.npz` format\n",
    "- `n_runs`: number of runs to do\n",
    "- `seed`: random seed to obtain reproducibile results and compare the importances matrices obtaind from the parallel and the serial version of the algorithm (they must be the same to certify the correctness of the parallel version)\n",
    "- `parallel`: Boolean variable used to choose between the parallel and the serial version of the algorithm\n",
    "- `n_cores`: Number of threads to use in the parallel version of the algorithm. This coincides with the number of cores set with the `--cpus-per-task` options in the `.job` file\n",
    "- `num_trees`: Number of trees used by ExIFFI. The higher the more complex and more computationally expensive the algorithm is\n",
    "- `name`: Name of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_exiffi(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    savedir,\n",
    "    n_runs=10,\n",
    "    seed=None,\n",
    "    parallel=False,\n",
    "    n_cores=2,\n",
    "    num_trees=300,\n",
    "    name=\"\",\n",
    "):\n",
    "    args_to_avoid = [\"X_train\", \"X_test\", \"savedir\", \"args_to_avoid\", \"args\"]\n",
    "    args = dict()\n",
    "    for k, v in locals().items():\n",
    "        if k in args_to_avoid:\n",
    "            continue\n",
    "        args[k] = v\n",
    "\n",
    "    ex_time = []\n",
    "    ex_imps = {}\n",
    "\n",
    "    for i in trange(n_runs):\n",
    "        seed = None if seed is None else seed + i\n",
    "\n",
    "        if parallel:\n",
    "            EDIFFI = Extended_DIFFI_parallel(\n",
    "                n_trees=num_trees, max_depth=100, subsample_size=256, plus=1, seed=seed\n",
    "            )\n",
    "            EDIFFI.set_num_processes(n_cores, n_cores)\n",
    "        else:\n",
    "            EDIFFI = Extended_DIFFI_original(\n",
    "                n_trees=num_trees, max_depth=100, subsample_size=256, plus=1, seed=seed\n",
    "            )\n",
    "\n",
    "        start = time.time()\n",
    "        imps = compute_imps(EDIFFI, X_train, X_test, 10)\n",
    "        ex_imps[\"Execution \" + str(i)] = imps\n",
    "        end = time.time()\n",
    "        ex_time.append(end - start)\n",
    "\n",
    "    # print(ex_imps)\n",
    "    time_stat = {\"mean\": np.mean(ex_time), \"std\": np.std(ex_time)}\n",
    "    filename = \"test_stat_parallel.npz\" if parallel else \"test_stat_serial.npz\"\n",
    "    t = time.localtime()\n",
    "    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n",
    "    filename = current_time + \"_\" + name + \"_\" + filename\n",
    "\n",
    "    # if dir does not exist, create it\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    filepath = os.path.join(savedir, filename)\n",
    "\n",
    "    np.savez(\n",
    "        filepath,\n",
    "        execution_time_stat=time_stat,\n",
    "        importances_matrix=ex_imps,\n",
    "        arguments=args,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129, 13), (129,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='wine'\n",
    "X,y=load_data(dataset_paths[name])\n",
    "X_train,X_test=partition_data(X,y)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.02it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "test_exiffi(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    savedir='../results/npz',\n",
    "    n_runs=1,\n",
    "    seed=120,\n",
    "    parallel=False,\n",
    "    n_cores=12,\n",
    "    num_trees=10,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exiffi(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    savedir='../results/npz',\n",
    "    n_runs=1,\n",
    "    seed=120,\n",
    "    parallel=True,\n",
    "    n_cores=12,\n",
    "    num_trees=200,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350, 33), (350,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='ionosphere'\n",
    "X,y=load_data(dataset_paths[name])\n",
    "X_train,X_test=partition_data(X,y)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exiffi(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    savedir='../results/npz',\n",
    "    n_runs=1,\n",
    "    seed=120,\n",
    "    parallel=False,\n",
    "    n_cores=12,\n",
    "    num_trees=10,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exiffi(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    savedir='../results/npz',\n",
    "    n_runs=1,\n",
    "    seed=120,\n",
    "    parallel=True,\n",
    "    n_cores=12,\n",
    "    num_trees=200,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moodify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((276260, 11), (276260,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='moodify'\n",
    "X,y=load_data_csv(dataset_paths[name])\n",
    "X_train,X_test=partition_data(X,y)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=np.load('26-01-2024_17-42-35_test_stat_parallel_7000.npz',allow_pickle=True)\n",
    "data_parallel=stats['importances_matrix'].tolist()\n",
    "time_data_parallel=stats['execution_time_stat']\n",
    "arguments_parallel=stats['arguments'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'X_test', 'X', 'n_runs', 'seed', 'parallel', 'n_cores'])\n",
      "n_runs 2\n",
      "seed None\n",
      "parallel True\n",
      "n_cores 8\n"
     ]
    }
   ],
   "source": [
    "print(arguments_parallel.keys())\n",
    "\n",
    "args_to_avoid = [\"X_train\", \"X_test\", \"X\"]\n",
    "for key in arguments_parallel.keys():\n",
    "    if key not in args_to_avoid:\n",
    "        print(key,arguments_parallel[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'mean': 3.36362202167511, 'std': 0.23129910849918273}, dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Execution 0', 'Execution 1', 'Execution 2', 'Execution 3', 'Execution 4', 'Execution 5', 'Execution 6', 'Execution 7', 'Execution 8', 'Execution 9'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parallel.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_stat_serial.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stats\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_stat_serial.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data_serial\u001b[38;5;241m=\u001b[39mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportances_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m time_data_serial\u001b[38;5;241m=\u001b[39mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecution_time_stat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_stat_serial.npz'"
     ]
    }
   ],
   "source": [
    "stats=np.load('test_stat_serial.npz',allow_pickle=True)\n",
    "data_serial=stats['importances_matrix'].tolist()\n",
    "time_data_serial=stats['execution_time_stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'mean': 3.5636572360992433, 'std': 0.5714168745774968},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data_serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Execution 0', 'Execution 1', 'Execution 2', 'Execution 3', 'Execution 4', 'Execution 5', 'Execution 6', 'Execution 7', 'Execution 8', 'Execution 9'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_serial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if `data_parallel` and `data_serial` are equal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.995204332975845e-14\n",
      "1.532107773982716e-13\n",
      "-3.4638958368304884e-13\n",
      "7.327471962526033e-14\n",
      "5.306866057708248e-13\n",
      "-3.774758283725532e-13\n",
      "-3.197442310920451e-13\n",
      "1.3522516439934407e-12\n",
      "-1.2434497875801753e-13\n",
      "-1.0769163338864018e-12\n"
     ]
    }
   ],
   "source": [
    "for k in data_serial.keys():\n",
    "    print(np.sum(data_serial[k]-data_parallel[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Thyroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'mean': 89.01771640777588, 'std': 0.0}, dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_runs': 1,\n",
       " 'seed': 120,\n",
       " 'parallel': True,\n",
       " 'n_cores': 2,\n",
       " 'num_trees': 10,\n",
       " 'name': 'annthyroid',\n",
       " 'args_to_avoid': ['X_train', 'X_test', 'savedir'],\n",
       " 'args': {...}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_load = (\n",
    "    \"../capri_code/results/npz/28-01-2024_17-45-18_annthyroid_test_stat_parallel.npz\"\n",
    ")\n",
    "\n",
    "stats = np.load(path_to_load, allow_pickle=True)\n",
    "\n",
    "display(stats['execution_time_stat'])\n",
    "display(stats['arguments'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'mean': 22.09242186546326, 'std': 2.2678216673392386}, dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_stats['execution_time_stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'n_runs': 10, 'seed': 120, 'parallel': True, 'n_cores': 12, 'num_trees': 300, 'name': 'wine', 'args_to_avoid': ['X_train', 'X_test', 'savedir'], 'args': {...}},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_stats['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_mat_wine=wine_stats['importances_matrix'].tolist()\n",
    "imp_mat_wine['Execution 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All results\n",
    "\n",
    "We use the script `process_results.py` to read the stats of the experiments from the `.npz` files and display them on a `pd.DataFrame` that can be saved as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breastw\n"
     ]
    }
   ],
   "source": [
    "for data in stats:\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cores_fit</th>\n",
       "      <th>n_cores_importance</th>\n",
       "      <th>n_cores_anomaly</th>\n",
       "      <th>n_runs</th>\n",
       "      <th>seed</th>\n",
       "      <th>parallel</th>\n",
       "      <th>n_trees</th>\n",
       "      <th>name</th>\n",
       "      <th>n_runs_imps</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>std_time</th>\n",
       "      <th>mean_MB</th>\n",
       "      <th>std_MB</th>\n",
       "      <th>max_MB</th>\n",
       "      <th>real_time</th>\n",
       "      <th>user_time</th>\n",
       "      <th>sys_time</th>\n",
       "      <th>cpu_efficiency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-30 14:43:40.063147</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>wine</td>\n",
       "      <td>1</td>\n",
       "      <td>3.917220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.368192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.368192</td>\n",
       "      <td>5.947</td>\n",
       "      <td>24.232</td>\n",
       "      <td>2.101</td>\n",
       "      <td>50.933244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 14:43:49.323403</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>glass</td>\n",
       "      <td>1</td>\n",
       "      <td>7.270264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>452.976640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>452.976640</td>\n",
       "      <td>9.257</td>\n",
       "      <td>44.005</td>\n",
       "      <td>2.526</td>\n",
       "      <td>59.421249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 14:41:30.894011</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>glass</td>\n",
       "      <td>2</td>\n",
       "      <td>14.008632</td>\n",
       "      <td>0.080843</td>\n",
       "      <td>475.654144</td>\n",
       "      <td>14.194033</td>\n",
       "      <td>484.184064</td>\n",
       "      <td>30.094</td>\n",
       "      <td>166.659</td>\n",
       "      <td>6.405</td>\n",
       "      <td>69.224347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 14:41:00.796146</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>wine</td>\n",
       "      <td>2</td>\n",
       "      <td>7.633811</td>\n",
       "      <td>0.063196</td>\n",
       "      <td>417.846272</td>\n",
       "      <td>10.626850</td>\n",
       "      <td>426.188800</td>\n",
       "      <td>17.117</td>\n",
       "      <td>89.760</td>\n",
       "      <td>4.994</td>\n",
       "      <td>65.548870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            n_cores_fit  n_cores_importance  n_cores_anomaly  \\\n",
       "time                                                                           \n",
       "2024-01-30 14:43:40.063147            8                   8                8   \n",
       "2024-01-30 14:43:49.323403            8                   8                8   \n",
       "2024-01-30 14:41:30.894011            8                   8                8   \n",
       "2024-01-30 14:41:00.796146            8                   8                8   \n",
       "\n",
       "                            n_runs  seed  parallel  n_trees   name  \\\n",
       "time                                                                 \n",
       "2024-01-30 14:43:40.063147       1  None      True      300   wine   \n",
       "2024-01-30 14:43:49.323403       1  None      True      300  glass   \n",
       "2024-01-30 14:41:30.894011       2  None      True      300  glass   \n",
       "2024-01-30 14:41:00.796146       2  None      True      300   wine   \n",
       "\n",
       "                            n_runs_imps  mean_time  std_time     mean_MB  \\\n",
       "time                                                                       \n",
       "2024-01-30 14:43:40.063147            1   3.917220  0.000000  399.368192   \n",
       "2024-01-30 14:43:49.323403            1   7.270264  0.000000  452.976640   \n",
       "2024-01-30 14:41:30.894011            2  14.008632  0.080843  475.654144   \n",
       "2024-01-30 14:41:00.796146            2   7.633811  0.063196  417.846272   \n",
       "\n",
       "                               std_MB      max_MB  real_time  user_time  \\\n",
       "time                                                                      \n",
       "2024-01-30 14:43:40.063147   0.000000  399.368192      5.947     24.232   \n",
       "2024-01-30 14:43:49.323403   0.000000  452.976640      9.257     44.005   \n",
       "2024-01-30 14:41:30.894011  14.194033  484.184064     30.094    166.659   \n",
       "2024-01-30 14:41:00.796146  10.626850  426.188800     17.117     89.760   \n",
       "\n",
       "                            sys_time  cpu_efficiency  \n",
       "time                                                  \n",
       "2024-01-30 14:43:40.063147     2.101       50.933244  \n",
       "2024-01-30 14:43:49.323403     2.526       59.421249  \n",
       "2024-01-30 14:41:30.894011     6.405       69.224347  \n",
       "2024-01-30 14:41:00.796146     4.994       65.548870  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from append_dir import append_dirname\n",
    "append_dirname('ExIFFI')\n",
    "\n",
    "from capri_code.process_results import load_stats, display_stats, compute_cpu_efficiency\n",
    "\n",
    "\n",
    "results_dirpath = \"../prova\"\n",
    "\n",
    "stats = load_stats(results_dirpath, use_pkl=True)\n",
    "\n",
    "for i, row in stats.iterrows():\n",
    "    n_cores = max([row[\"n_cores_fit\"], row[\"n_cores_importance\"], row[\"n_cores_anomaly\"]])\n",
    "    stats.loc[i, \"cpu_efficiency\"] = compute_cpu_efficiency(row[\"real_time\"], row[\"user_time\"], n_cores)\n",
    "    \n",
    "\n",
    "display_stats(stats)\n",
    "# display_stats(stats.groupby(\"name\").get_group(\"cardio\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'importances_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# display_stats(stats)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m display(stats)\n\u001b[0;32m---> 15\u001b[0m imps_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimportances_matrix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimps_mat.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, imps_mat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m imp_mat_ex_0 \u001b[38;5;241m=\u001b[39m imps_mat[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/pandas/core/indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/pandas/core/frame.py:4202\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4199\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[0;32m-> 4202\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4203\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4206\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4207\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4208\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/pandas/core/frame.py:4626\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4621\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[1;32m   4622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4623\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4624\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[0;32m-> 4626\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4627\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4629\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'importances_matrix'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from append_dir import append_dirname\n",
    "append_dirname('ExIFFI')\n",
    "\n",
    "from capri_code.process_results import load_stats, display_stats\n",
    "\n",
    "\n",
    "results_dirpath = \"../capri_code/results/npz/new/new\"\n",
    "\n",
    "stats = load_stats(results_dirpath)\n",
    "\n",
    "# display_stats(stats)\n",
    "display(stats)\n",
    "\n",
    "imps_mat = np.array(stats.loc[0, \"importances_matrix\"])\n",
    "\n",
    "print(\"imps_mat.shape\", imps_mat.shape)\n",
    "\n",
    "\n",
    "imp_mat_ex_0 = imps_mat[0]\n",
    "print(\"imp_mat_ex_0.shape\", imp_mat_ex_0.shape)\n",
    "\n",
    "# for i in range(len(imp_mat_ex_0)-1):\n",
    "#     print(imp_mat_ex_0[i] - imp_mat_ex_0[i+1])\n",
    "\n",
    "imp_mat_ex_1 = imps_mat[1]\n",
    "\n",
    "# for i in range(len(imp_mat_ex_1)):\n",
    "#     print(imp_mat_ex_1[i] - imp_mat_ex_0[i])\n",
    "\n",
    "# print(imps_mat[0] - imps_mat[1])\n",
    "# print(imps_mat[1] - imps_mat[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "(3, 1)\n",
      "output\n",
      " [[11.]\n",
      " [11.]\n",
      " [11.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return x+10\n",
    "\n",
    "a = np.ones((3))\n",
    "\n",
    "# add newaxis to a\n",
    "a = a[:, np.newaxis]\n",
    "\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "output = np.apply_along_axis(func, 1, a)\n",
    "\n",
    "print(\"output\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-01-29 14:52:25.715026')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# current datetime\n",
    "import datetime\n",
    "\n",
    "# datetime compatible with pandas dataframe rows\n",
    "import pandas as pd\n",
    "datetime_row_pandas = pd.Timestamp.now()\n",
    "\n",
    "datetime_row_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/container/job2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../../container/job2/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Parallel python script:\n",
      "############################################################\n",
      "TESTING PARALLEL ExIFFI\n",
      "############################################################\n",
      "TEST PARAMETERS:\n",
      "Number of runs: 1\n",
      "Number of trees: 100\n",
      "Number of cores: fit 8, importance 8, anomaly 8\n",
      "Seed: 120\n",
      "Parallel: True\n",
      "############################################################\n",
      "dataset_names ['wine']\n",
      "############################################################\n",
      "DATASET: wine\n",
      "############################################################\n",
      "Experiment:   0%|                                         | 0/1 [00:00<?, ?it/s]Execution 1\n",
      "Set up Extended_DIFFI_parallel\n",
      "Finished setting up Extended_DIFFI_parallel\n",
      "Call compute_imps\n",
      "shape of X_train: (119, 13)\n",
      "shape of X_test: (129, 13)\n",
      "\n",
      "Fit & Importances:   0%|                                 | 0/10 [00:00<?, ?it/s]\u001b[AStart fit\n",
      "End fit\n",
      "Start Global Importance\n",
      "Start computing Anomaly Score\n",
      "End computing Anomaly Score\n",
      "Start computing Importances Score\n",
      "self.num_processes_importances: 8\n",
      "segment_size: 12\n",
      "Segments shapes: [(12,), (12,), (12,), (12,), (12,), (12,), (12,), (12,), (4,)]\n",
      "Stop computing Importances Score\n",
      "End Global Importance\n",
      "\n",
      "Fit & Importances:  10%|██▌                      | 1/10 [00:01<00:14,  1.59s/it]\u001b[AStart fit\n",
      "End fit\n",
      "Start Global Importance\n",
      "Start computing Anomaly Score\n",
      "End computing Anomaly Score\n",
      "Start computing Importances Score\n",
      "self.num_processes_importances: 8\n",
      "segment_size: 12\n",
      "Segments shapes: [(12,), (12,), (12,), (12,), (12,), (12,), (12,), (12,), (4,)]\n",
      "Stop computing Importances Score\n",
      "End Global Importance\n",
      "\n",
      "Fit & Importances:  20%|█████                    | 2/10 [00:02<00:11,  1.42s/it]\u001b[AStart fit\n",
      "End fit\n",
      "Start Global Importance\n",
      "Start computing Anomaly Score\n",
      "^C\n",
      "Process ForkPoolWorker-62:\n",
      "Process ForkPoolWorker-61:\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-58:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-64:\n",
      "Process ForkPoolWorker-63:\n",
      "Process ForkPoolWorker-57:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 345, in path\n",
      "    if val:\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 343, in path\n",
      "    while s is not None:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 344, in path\n",
      "    val = x.dot(n)-s>0\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 344, in path\n",
      "    val = x.dot(n)-s>0\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 344, in path\n",
      "    val = x.dot(n)-s>0\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! ./exec_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'subprocess' has no attribute 'STDERR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Your Python script code here\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Execute the time command and capture the output\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m time_output \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./exec_parallel.sh\u001b[39m\u001b[38;5;124m\"\u001b[39m], stderr\u001b[38;5;241m=\u001b[39m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDERR\u001b[49m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Save the time output to a file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_output_err.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'subprocess' has no attribute 'STDERR'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Your Python script code here\n",
    "\n",
    "# Execute the time command and capture the output\n",
    "time_output = subprocess.check_output([\"./exec_parallel.sh\"], tsderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "# Save the time output to a file\n",
    "with open(\"time_output_err.txt\", \"w\") as file:\n",
    "    file.write(time_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['real', '0m13.487s'], ['user', '0m52.816s'], ['sys', '0m7.766s']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.split('\\t') for i in time_output.split(\"\\n\")[-4:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/capri_code'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../capri_code/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Fit & Importances:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Fit & Importances: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\u001b[A\n",
      "Experiment: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "TESTING PARALLEL ExIFFI\n",
      "############################################################\n",
      "TEST PARAMETERS:\n",
      "Number of runs: 1\n",
      "Number of trees: 300\n",
      "Number of cores: fit 12, importance 12, anomaly 12\n",
      "Seed: 123\n",
      "Parallel: True\n",
      "############################################################\n",
      "dataset_names ['wine']\n",
      "############################################################\n",
      "DATASET: wine\n",
      "############################################################\n",
      "Execution 1\n",
      "Set up Extended_DIFFI_parallel\n",
      "Finished setting up Extended_DIFFI_parallel\n",
      "Call compute_imps\n",
      "shape of X_train: (119, 13)\n",
      "shape of X_test: (129, 13)\n",
      "Start fit\n",
      "End fit\n",
      "Start Global Importance\n",
      "Start computing Anomaly Score\n",
      "End computing Anomaly Score\n",
      "Start computing Importances Score\n",
      "self.num_processes_importances: 12\n",
      "segment_size: 25\n",
      "Segments shapes: [(25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,)]\n",
      "Stop computing Importances Score\n",
      "End Global Importance\n",
      "End call compute_imps\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18.24user 2.70system 0:05.03elapsed 416%CPU (0avgtext+0avgdata 369980maxresident)k\n",
      "0inputs+16outputs (2major+321682minor)pagefaults 0swaps\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Your shell command as a string\n",
    "shell_command = 'time python test_parallel.py --n_runs 1 --savedir ./results/npz/new  --n_trees 300  --dataset_names wine --n_cores 12 --seed 123 --n_runs_imps 1'\n",
    "\n",
    "# Execute the command and capture the output\n",
    "output = subprocess.check_output(shell_command, shell=True, text=True)\n",
    "\n",
    "# Print or use the captured output as needed\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"############################################################\\nTESTING PARALLEL ExIFFI\\n############################################################\\nTEST PARAMETERS:\\nNumber of runs: 1\\nNumber of trees: 300\\nNumber of cores: fit 12, importance 12, anomaly 12\\nSeed: 123\\nParallel: True\\n############################################################\\ndataset_names ['wine']\\n############################################################\\nDATASET: wine\\n############################################################\\nExecution 1\\nSet up Extended_DIFFI_parallel\\nFinished setting up Extended_DIFFI_parallel\\nCall compute_imps\\nshape of X_train: (119, 13)\\nshape of X_test: (129, 13)\\nStart fit\\nEnd fit\\nStart Global Importance\\nStart computing Anomaly Score\\nEnd computing Anomaly Score\\nStart computing Importances Score\\nself.num_processes_importances: 12\\nsegment_size: 25\\nSegments shapes: [(25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,)]\\nStop computing Importances Score\\nEnd Global Importance\\nEnd call compute_imps\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/capri_code/results/npz/new'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "os.chdir('../capri_code/results/npz/new/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29-01-2024_14-40-58_annthyroid_test_stat_parallel.npz', '29-01-2024_16-59-18_wine_test_stat_parallel.npz', '29-01-2024_14-12-35_wine_test_stat_parallel.npz', '29-01-2024_17-02-05_wine_test_stat_parallel.npz', '29-01-2024_12-51-07_cardio_test_stat_parallel.npz', '29-01-2024_19-17-38_test_stat_parallel_wine.npz', '29-01-2024_14-14-24_wine_test_stat_parallel.npz', '29-01-2024_16-59-47_wine_test_stat_parallel.npz', '29-01-2024_18-21-27_wine_test_stat_parallel.npz', '29-01-2024_18-22-40_wine_test_stat_parallel.npz', '29-01-2024_14-56-08_wine_test_stat_parallel.npz', '29-01-2024_18-10-56_wine_test_stat_parallel.npz', '29-01-2024_19-14-07_wine_test_stat_parallel.npz', '29-01-2024_14-13-43_wine_test_stat_parallel.npz', '29-01-2024_12-47-38_wine_test_stat_parallel.npz', '29-01-2024_19-15-44_test_stat_parallel_wine.npz', '29-01-2024_18-16-09_wine_test_stat_parallel.npz', '29-01-2024_14-07-57_wine_test_stat_parallel.npz', '29-01-2024_14-31-29_wine_test_stat_parallel.npz', '29-01-2024_16-49-37_wine_test_stat_parallel.npz', '29-01-2024_14-11-27_wine_test_stat_parallel.npz', '29-01-2024_18-23-34_wine_test_stat_parallel.npz', '29-01-2024_12-48-59_wine_test_stat_parallel.npz', '29-01-2024_12-49-23_breastw_test_stat_parallel.npz', '29-01-2024_18-12-21_wine_test_stat_parallel.npz', '29-01-2024_12-47-58_wine_test_stat_parallel.npz']\n"
     ]
    }
   ],
   "source": [
    "search_word = \"29-01-2024\"\n",
    "pattern = f\"*{search_word}*\"\n",
    "\n",
    "matching_files = glob(pattern)\n",
    "print(matching_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=np.load('30-01-2024_10-07-13_test_stat_parallel_wine.npz',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'execution_time_stat is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexecution_time_stat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/npyio.py:260\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'execution_time_stat is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "stats['execution_time_stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
