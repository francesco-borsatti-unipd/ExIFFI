{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Host capri Davide\n",
    "\n",
    "    Hostname capri.dei.unipd.it\n",
    "    User p1026u27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from append_dir import append_dirname\n",
    "append_dirname('ExIFFI')\n",
    "from utils.utils import partition_data\n",
    "from utils.feature_selection import *\n",
    "#from plot import *\n",
    "#from simulation_setup import *\n",
    "from models import *\n",
    "from models.Extended_IF import *\n",
    "from models.Extended_DIFFI_parallel import *\n",
    "from models.Extended_DIFFI_original import *\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "import os\n",
    "import pickle \n",
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = os.path.dirname(path)\n",
    "path_real = os.path.join(path, \"data\", \"real\")\n",
    "mat_files_real = glob(os.path.join(path_real, \"*.mat\"))\n",
    "mat_file_names_real = {os.path.basename(x).split(\".\")[0]: x for x in mat_files_real}\n",
    "csv_files_real = glob(os.path.join(path_real, \"*.csv\"))\n",
    "csv_file_names_real = {os.path.basename(x).split(\".\")[0]: x for x in csv_files_real}\n",
    "dataset_names = list(mat_file_names_real.keys()) + list(csv_file_names_real.keys())\n",
    "mat_file_names_real.update(csv_file_names_real)\n",
    "dataset_paths = mat_file_names_real.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicates from the loaded dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(X, y):\n",
    "    S = np.c_[X, y]\n",
    "    S = pd.DataFrame(S).drop_duplicates().to_numpy()\n",
    "    X, y = S[:, :-1], S[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset coming from a `.mat` file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = loadmat(path)\n",
    "    X, y = data[\"X\"], data[\"y\"]\n",
    "    y = np.hstack(y)\n",
    "    X, y = drop_duplicates(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset coming from a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_csv(path):\n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    if \"Unnamed: 0\" in data.columns:\n",
    "        data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    X = data[data.columns[data.columns != \"Target\"]]\n",
    "    y = data[\"Target\"]\n",
    "\n",
    "    X, y = drop_duplicates(X, y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data (with `load_data` or with `load_data_csv`), scale the data and split it into train and test set obtaining `X_train`, `X_test` that will be passed to `compute_imps`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(path):\n",
    "    extension = os.path.splitext(path)[1]\n",
    "\n",
    "    if extension == \".csv\":\n",
    "        X, y = load_data_csv(path)\n",
    "    elif extension == \".mat\":\n",
    "        X, y = load_data(path)\n",
    "    else:\n",
    "        raise ValueError(\"Extension not supported\")\n",
    "\n",
    "    X_train, X_test = partition_data(X, y)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test = np.r_[X_train, X_test]\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Global Importance of a given dataset `n_runs` times. At the end a matrix with shape `(n_runs, n_features)` is returned. Each row contains the global importance of the features for a given run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_imps(model, X_train, X_test, n_runs):\n",
    "\n",
    "    X_test=np.r_[X_train,X_test]\n",
    "\n",
    "    imps = np.zeros(shape=(n_runs, X_train.shape[1]))\n",
    "    for i in tqdm(range(n_runs)):\n",
    "        model.fit(X_train)\n",
    "        imps[i, :] = model.Global_importance(\n",
    "            X_test, calculate=True, overwrite=False, depth_based=False\n",
    "        )\n",
    "\n",
    "    return imps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `test_exiffi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function called in the `main` of `test_parallel.py` used to do the experiments on the CAPRI HPC server. For a given set of datasets it computes the global importance `n_runs` times using `Extended_DIFFI_parallel` or `Extended_DIFFI_original`and saves the importances matrices, the time stats obtained and the test arguments in a `.npz` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `test_exiffi` Parameters\n",
    "\n",
    "- `X_train`: the train set\n",
    "- `X_test`: the test set\n",
    "- `savedir`: directory where to save the results in `.npz` format\n",
    "- `n_runs`: number of runs to do\n",
    "- `seed`: random seed to obtain reproducibile results and compare the importances matrices obtaind from the parallel and the serial version of the algorithm (they must be the same to certify the correctness of the parallel version)\n",
    "- `parallel`: Boolean variable used to choose between the parallel and the serial version of the algorithm\n",
    "- `n_cores`: Number of threads to use in the parallel version of the algorithm. This coincides with the number of cores set with the `--cpus-per-task` options in the `.job` file\n",
    "- `num_trees`: Number of trees used by ExIFFI. The higher the more complex and more computationally expensive the algorithm is\n",
    "- `name`: Name of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_exiffi(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    savedir,\n",
    "    n_runs=10,\n",
    "    seed=None,\n",
    "    parallel=False,\n",
    "    n_cores=2,\n",
    "    num_trees=300,\n",
    "    name=\"\",\n",
    "):\n",
    "    args_to_avoid = [\"X_train\", \"X_test\", \"savedir\", \"args_to_avoid\", \"args\"]\n",
    "    args = dict()\n",
    "    for k, v in locals().items():\n",
    "        if k in args_to_avoid:\n",
    "            continue\n",
    "        args[k] = v\n",
    "\n",
    "    ex_time = []\n",
    "    ex_imps = {}\n",
    "\n",
    "    for i in trange(n_runs):\n",
    "        seed = None if seed is None else seed + i\n",
    "\n",
    "        if parallel:\n",
    "            EDIFFI = Extended_DIFFI_parallel(\n",
    "                n_trees=num_trees, max_depth=100, subsample_size=256, plus=1, seed=seed\n",
    "            )\n",
    "            EDIFFI.set_num_processes(n_cores, n_cores)\n",
    "        else:\n",
    "            EDIFFI = Extended_DIFFI_original(\n",
    "                n_trees=num_trees, max_depth=100, subsample_size=256, plus=1, seed=seed\n",
    "            )\n",
    "\n",
    "        start = time.time()\n",
    "        imps = compute_imps(EDIFFI, X_train, X_test, 10)\n",
    "        ex_imps[\"Execution \" + str(i)] = imps\n",
    "        end = time.time()\n",
    "        ex_time.append(end - start)\n",
    "\n",
    "    # print(ex_imps)\n",
    "    time_stat = {\"mean\": np.mean(ex_time), \"std\": np.std(ex_time)}\n",
    "    filename = \"test_stat_parallel.npz\" if parallel else \"test_stat_serial.npz\"\n",
    "    t = time.localtime()\n",
    "    current_time = time.strftime(\"%d-%m-%Y_%H-%M-%S\", t)\n",
    "    filename = current_time + \"_\" + name + \"_\" + filename\n",
    "\n",
    "    # if dir does not exist, create it\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    filepath = os.path.join(savedir, filename)\n",
    "\n",
    "    np.savez(\n",
    "        filepath,\n",
    "        execution_time_stat=time_stat,\n",
    "        importances_matrix=ex_imps,\n",
    "        arguments=args,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129, 13), (129,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='wine'\n",
    "X,y=load_data(dataset_paths[name])\n",
    "X_train,X_test=partition_data(X,y)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.02it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "test_exiffi(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    savedir='../results/npz',\n",
    "    n_runs=1,\n",
    "    seed=120,\n",
    "    parallel=False,\n",
    "    n_cores=12,\n",
    "    num_trees=10,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exiffi(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    savedir='../results/npz',\n",
    "    n_runs=1,\n",
    "    seed=120,\n",
    "    parallel=True,\n",
    "    n_cores=12,\n",
    "    num_trees=200,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350, 33), (350,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='ionosphere'\n",
    "X,y=load_data(dataset_paths[name])\n",
    "X_train,X_test=partition_data(X,y)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exiffi(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    savedir='../results/npz',\n",
    "    n_runs=1,\n",
    "    seed=120,\n",
    "    parallel=False,\n",
    "    n_cores=12,\n",
    "    num_trees=10,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exiffi(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    savedir='../results/npz',\n",
    "    n_runs=1,\n",
    "    seed=120,\n",
    "    parallel=True,\n",
    "    n_cores=12,\n",
    "    num_trees=200,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moodify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((276260, 11), (276260,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='moodify'\n",
    "X,y=load_data_csv(dataset_paths[name])\n",
    "X_train,X_test=partition_data(X,y)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=np.load('26-01-2024_17-42-35_test_stat_parallel_7000.npz',allow_pickle=True)\n",
    "data_parallel=stats['importances_matrix'].tolist()\n",
    "time_data_parallel=stats['execution_time_stat']\n",
    "arguments_parallel=stats['arguments'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'X_test', 'X', 'n_runs', 'seed', 'parallel', 'n_cores'])\n",
      "n_runs 2\n",
      "seed None\n",
      "parallel True\n",
      "n_cores 8\n"
     ]
    }
   ],
   "source": [
    "print(arguments_parallel.keys())\n",
    "\n",
    "args_to_avoid = [\"X_train\", \"X_test\", \"X\"]\n",
    "for key in arguments_parallel.keys():\n",
    "    if key not in args_to_avoid:\n",
    "        print(key,arguments_parallel[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'mean': 3.36362202167511, 'std': 0.23129910849918273}, dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Execution 0', 'Execution 1', 'Execution 2', 'Execution 3', 'Execution 4', 'Execution 5', 'Execution 6', 'Execution 7', 'Execution 8', 'Execution 9'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parallel.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_stat_serial.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stats\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_stat_serial.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data_serial\u001b[38;5;241m=\u001b[39mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportances_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m time_data_serial\u001b[38;5;241m=\u001b[39mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecution_time_stat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_stat_serial.npz'"
     ]
    }
   ],
   "source": [
    "stats=np.load('test_stat_serial.npz',allow_pickle=True)\n",
    "data_serial=stats['importances_matrix'].tolist()\n",
    "time_data_serial=stats['execution_time_stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'mean': 3.5636572360992433, 'std': 0.5714168745774968},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_data_serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Execution 0', 'Execution 1', 'Execution 2', 'Execution 3', 'Execution 4', 'Execution 5', 'Execution 6', 'Execution 7', 'Execution 8', 'Execution 9'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_serial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if `data_parallel` and `data_serial` are equal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.995204332975845e-14\n",
      "1.532107773982716e-13\n",
      "-3.4638958368304884e-13\n",
      "7.327471962526033e-14\n",
      "5.306866057708248e-13\n",
      "-3.774758283725532e-13\n",
      "-3.197442310920451e-13\n",
      "1.3522516439934407e-12\n",
      "-1.2434497875801753e-13\n",
      "-1.0769163338864018e-12\n"
     ]
    }
   ],
   "source": [
    "for k in data_serial.keys():\n",
    "    print(np.sum(data_serial[k]-data_parallel[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Thyroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'mean': 89.01771640777588, 'std': 0.0}, dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_runs': 1,\n",
       " 'seed': 120,\n",
       " 'parallel': True,\n",
       " 'n_cores': 2,\n",
       " 'num_trees': 10,\n",
       " 'name': 'annthyroid',\n",
       " 'args_to_avoid': ['X_train', 'X_test', 'savedir'],\n",
       " 'args': {...}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_load = (\n",
    "    \"../capri_code/results/npz/28-01-2024_17-45-18_annthyroid_test_stat_parallel.npz\"\n",
    ")\n",
    "\n",
    "stats = np.load(path_to_load, allow_pickle=True)\n",
    "\n",
    "display(stats['execution_time_stat'])\n",
    "display(stats['arguments'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'mean': 22.09242186546326, 'std': 2.2678216673392386}, dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_stats['execution_time_stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'n_runs': 10, 'seed': 120, 'parallel': True, 'n_cores': 12, 'num_trees': 300, 'name': 'wine', 'args_to_avoid': ['X_train', 'X_test', 'savedir'], 'args': {...}},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_stats['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484],\n",
       "       [1.51150254, 0.94012808, 0.77765704, 0.85334869, 0.92756969,\n",
       "        1.01631053, 1.27235724, 1.37869805, 0.93163375, 1.2656863 ,\n",
       "        1.18378956, 1.39478296, 1.38035484]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_mat_wine=wine_stats['importances_matrix'].tolist()\n",
    "imp_mat_wine['Execution 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All results\n",
    "\n",
    "We use the script `process_results.py` to read the stats of the experiments from the `.npz` files and display them on a `pd.DataFrame` that can be saved as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breastw\n"
     ]
    }
   ],
   "source": [
    "for data in stats:\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cores_fit</th>\n",
       "      <th>n_cores_importance</th>\n",
       "      <th>n_cores_anomaly</th>\n",
       "      <th>n_runs</th>\n",
       "      <th>seed</th>\n",
       "      <th>parallel</th>\n",
       "      <th>n_trees</th>\n",
       "      <th>name</th>\n",
       "      <th>n_runs_imps</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>std_time</th>\n",
       "      <th>mean_MB</th>\n",
       "      <th>std_MB</th>\n",
       "      <th>max_MB</th>\n",
       "      <th>real_time</th>\n",
       "      <th>user_time</th>\n",
       "      <th>sys_time</th>\n",
       "      <th>cpu_efficiency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-30 15:47:36.088014</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>wine</td>\n",
       "      <td>5</td>\n",
       "      <td>65.135395</td>\n",
       "      <td>1.783640</td>\n",
       "      <td>421.945016</td>\n",
       "      <td>3.925508</td>\n",
       "      <td>428.290048</td>\n",
       "      <td>327.901</td>\n",
       "      <td>340.537</td>\n",
       "      <td>9.254</td>\n",
       "      <td>25.963401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 15:35:08.255912</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>wine</td>\n",
       "      <td>5</td>\n",
       "      <td>36.076435</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>443.505377</td>\n",
       "      <td>11.205296</td>\n",
       "      <td>466.964480</td>\n",
       "      <td>182.849</td>\n",
       "      <td>347.223</td>\n",
       "      <td>10.888</td>\n",
       "      <td>47.474009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 15:57:14.231006</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>glass</td>\n",
       "      <td>5</td>\n",
       "      <td>115.173798</td>\n",
       "      <td>1.689243</td>\n",
       "      <td>489.580954</td>\n",
       "      <td>6.211631</td>\n",
       "      <td>500.228096</td>\n",
       "      <td>578.169</td>\n",
       "      <td>602.999</td>\n",
       "      <td>12.623</td>\n",
       "      <td>26.073648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 15:40:41.691636</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>glass</td>\n",
       "      <td>5</td>\n",
       "      <td>65.843605</td>\n",
       "      <td>0.978784</td>\n",
       "      <td>421.421711</td>\n",
       "      <td>24.829751</td>\n",
       "      <td>494.878720</td>\n",
       "      <td>331.750</td>\n",
       "      <td>615.674</td>\n",
       "      <td>14.859</td>\n",
       "      <td>46.395931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 16:50:32.736658</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>cardio</td>\n",
       "      <td>5</td>\n",
       "      <td>380.160016</td>\n",
       "      <td>1.962829</td>\n",
       "      <td>736.371671</td>\n",
       "      <td>33.649745</td>\n",
       "      <td>762.687488</td>\n",
       "      <td>1908.615</td>\n",
       "      <td>2271.178</td>\n",
       "      <td>24.292</td>\n",
       "      <td>29.749033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            n_cores_fit  n_cores_importance  n_cores_anomaly  \\\n",
       "time                                                                           \n",
       "2024-01-30 15:47:36.088014            1                   1                4   \n",
       "2024-01-30 15:35:08.255912            4                   1                1   \n",
       "2024-01-30 15:57:14.231006            1                   1                4   \n",
       "2024-01-30 15:40:41.691636            4                   1                1   \n",
       "2024-01-30 16:50:32.736658            4                   1                1   \n",
       "\n",
       "                            n_runs  seed  parallel  n_trees    name  \\\n",
       "time                                                                  \n",
       "2024-01-30 15:47:36.088014       5   120      True      300    wine   \n",
       "2024-01-30 15:35:08.255912       5   120      True      300    wine   \n",
       "2024-01-30 15:57:14.231006       5   120      True      300   glass   \n",
       "2024-01-30 15:40:41.691636       5   120      True      300   glass   \n",
       "2024-01-30 16:50:32.736658       5   120      True      300  cardio   \n",
       "\n",
       "                            n_runs_imps   mean_time  std_time     mean_MB  \\\n",
       "time                                                                        \n",
       "2024-01-30 15:47:36.088014            5   65.135395  1.783640  421.945016   \n",
       "2024-01-30 15:35:08.255912            5   36.076435  0.999008  443.505377   \n",
       "2024-01-30 15:57:14.231006            5  115.173798  1.689243  489.580954   \n",
       "2024-01-30 15:40:41.691636            5   65.843605  0.978784  421.421711   \n",
       "2024-01-30 16:50:32.736658            5  380.160016  1.962829  736.371671   \n",
       "\n",
       "                               std_MB      max_MB  real_time  user_time  \\\n",
       "time                                                                      \n",
       "2024-01-30 15:47:36.088014   3.925508  428.290048    327.901    340.537   \n",
       "2024-01-30 15:35:08.255912  11.205296  466.964480    182.849    347.223   \n",
       "2024-01-30 15:57:14.231006   6.211631  500.228096    578.169    602.999   \n",
       "2024-01-30 15:40:41.691636  24.829751  494.878720    331.750    615.674   \n",
       "2024-01-30 16:50:32.736658  33.649745  762.687488   1908.615   2271.178   \n",
       "\n",
       "                            sys_time  cpu_efficiency  \n",
       "time                                                  \n",
       "2024-01-30 15:47:36.088014     9.254       25.963401  \n",
       "2024-01-30 15:35:08.255912    10.888       47.474009  \n",
       "2024-01-30 15:57:14.231006    12.623       26.073648  \n",
       "2024-01-30 15:40:41.691636    14.859       46.395931  \n",
       "2024-01-30 16:50:32.736658    24.292       29.749033  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cores_fit</th>\n",
       "      <th>n_cores_importance</th>\n",
       "      <th>n_cores_anomaly</th>\n",
       "      <th>n_runs</th>\n",
       "      <th>seed</th>\n",
       "      <th>parallel</th>\n",
       "      <th>n_trees</th>\n",
       "      <th>name</th>\n",
       "      <th>n_runs_imps</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>std_time</th>\n",
       "      <th>mean_MB</th>\n",
       "      <th>std_MB</th>\n",
       "      <th>max_MB</th>\n",
       "      <th>real_time</th>\n",
       "      <th>user_time</th>\n",
       "      <th>sys_time</th>\n",
       "      <th>cpu_efficiency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-30 17:07:52.333205</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>cardio</td>\n",
       "      <td>5</td>\n",
       "      <td>437.642479</td>\n",
       "      <td>18.793363</td>\n",
       "      <td>591.404073</td>\n",
       "      <td>9.619989</td>\n",
       "      <td>608.174080</td>\n",
       "      <td>2190.869</td>\n",
       "      <td>2184.656</td>\n",
       "      <td>5.743</td>\n",
       "      <td>99.716414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 16:22:03.105891</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>wine</td>\n",
       "      <td>5</td>\n",
       "      <td>65.463616</td>\n",
       "      <td>4.144099</td>\n",
       "      <td>404.238664</td>\n",
       "      <td>2.465636</td>\n",
       "      <td>407.486464</td>\n",
       "      <td>329.567</td>\n",
       "      <td>327.989</td>\n",
       "      <td>1.480</td>\n",
       "      <td>99.521190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 16:31:21.686496</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>glass</td>\n",
       "      <td>5</td>\n",
       "      <td>111.261842</td>\n",
       "      <td>7.624729</td>\n",
       "      <td>470.430024</td>\n",
       "      <td>8.476952</td>\n",
       "      <td>480.997376</td>\n",
       "      <td>558.595</td>\n",
       "      <td>555.479</td>\n",
       "      <td>2.952</td>\n",
       "      <td>99.442172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 15:49:56.673645</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>cardio</td>\n",
       "      <td>5</td>\n",
       "      <td>142.643763</td>\n",
       "      <td>8.523221</td>\n",
       "      <td>393.009725</td>\n",
       "      <td>1.838510</td>\n",
       "      <td>395.968512</td>\n",
       "      <td>716.112</td>\n",
       "      <td>712.554</td>\n",
       "      <td>1.992</td>\n",
       "      <td>99.503150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 15:34:38.531939</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>wine</td>\n",
       "      <td>5</td>\n",
       "      <td>22.670529</td>\n",
       "      <td>1.310402</td>\n",
       "      <td>326.859817</td>\n",
       "      <td>7.030727</td>\n",
       "      <td>333.770752</td>\n",
       "      <td>120.767</td>\n",
       "      <td>113.376</td>\n",
       "      <td>0.583</td>\n",
       "      <td>93.879951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 15:37:59.648176</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>glass</td>\n",
       "      <td>5</td>\n",
       "      <td>38.201773</td>\n",
       "      <td>1.994781</td>\n",
       "      <td>258.565734</td>\n",
       "      <td>48.463303</td>\n",
       "      <td>355.602432</td>\n",
       "      <td>199.292</td>\n",
       "      <td>192.154</td>\n",
       "      <td>1.794</td>\n",
       "      <td>96.418321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            n_cores_fit  n_cores_importance  n_cores_anomaly  \\\n",
       "time                                                                           \n",
       "2024-01-30 17:07:52.333205            1                   1                1   \n",
       "2024-01-30 16:22:03.105891            1                   1                1   \n",
       "2024-01-30 16:31:21.686496            1                   1                1   \n",
       "2024-01-30 15:49:56.673645            1                   1                1   \n",
       "2024-01-30 15:34:38.531939            1                   1                1   \n",
       "2024-01-30 15:37:59.648176            1                   1                1   \n",
       "\n",
       "                            n_runs  seed  parallel  n_trees    name  \\\n",
       "time                                                                  \n",
       "2024-01-30 17:07:52.333205       5   120     False      300  cardio   \n",
       "2024-01-30 16:22:03.105891       5   120     False      300    wine   \n",
       "2024-01-30 16:31:21.686496       5   120     False      300   glass   \n",
       "2024-01-30 15:49:56.673645       5   120     False      100  cardio   \n",
       "2024-01-30 15:34:38.531939       5   120     False      100    wine   \n",
       "2024-01-30 15:37:59.648176       5   120     False      100   glass   \n",
       "\n",
       "                            n_runs_imps   mean_time   std_time     mean_MB  \\\n",
       "time                                                                         \n",
       "2024-01-30 17:07:52.333205            5  437.642479  18.793363  591.404073   \n",
       "2024-01-30 16:22:03.105891            5   65.463616   4.144099  404.238664   \n",
       "2024-01-30 16:31:21.686496            5  111.261842   7.624729  470.430024   \n",
       "2024-01-30 15:49:56.673645            5  142.643763   8.523221  393.009725   \n",
       "2024-01-30 15:34:38.531939            5   22.670529   1.310402  326.859817   \n",
       "2024-01-30 15:37:59.648176            5   38.201773   1.994781  258.565734   \n",
       "\n",
       "                               std_MB      max_MB  real_time  user_time  \\\n",
       "time                                                                      \n",
       "2024-01-30 17:07:52.333205   9.619989  608.174080   2190.869   2184.656   \n",
       "2024-01-30 16:22:03.105891   2.465636  407.486464    329.567    327.989   \n",
       "2024-01-30 16:31:21.686496   8.476952  480.997376    558.595    555.479   \n",
       "2024-01-30 15:49:56.673645   1.838510  395.968512    716.112    712.554   \n",
       "2024-01-30 15:34:38.531939   7.030727  333.770752    120.767    113.376   \n",
       "2024-01-30 15:37:59.648176  48.463303  355.602432    199.292    192.154   \n",
       "\n",
       "                            sys_time  cpu_efficiency  \n",
       "time                                                  \n",
       "2024-01-30 17:07:52.333205     5.743       99.716414  \n",
       "2024-01-30 16:22:03.105891     1.480       99.521190  \n",
       "2024-01-30 16:31:21.686496     2.952       99.442172  \n",
       "2024-01-30 15:49:56.673645     1.992       99.503150  \n",
       "2024-01-30 15:34:38.531939     0.583       93.879951  \n",
       "2024-01-30 15:37:59.648176     1.794       96.418321  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from append_dir import append_dirname\n",
    "append_dirname('ExIFFI')\n",
    "\n",
    "from capri_code.process_results import load_stats, display_stats, compute_cpu_efficiency\n",
    "\n",
    "\n",
    "results_dirpath = \"../../container/job4/results/\"\n",
    "\n",
    "stats = load_stats(results_dirpath, use_pkl=True)\n",
    "\n",
    "for i, row in stats.iterrows():\n",
    "    n_cores = max([row[\"n_cores_fit\"], row[\"n_cores_importance\"], row[\"n_cores_anomaly\"]])\n",
    "    stats.loc[i, \"cpu_efficiency\"] = compute_cpu_efficiency(row[\"real_time\"], row[\"user_time\"], n_cores)\n",
    "    \n",
    "\n",
    "# display_stats(stats)\n",
    "display_stats(stats.groupby(\"parallel\").get_group(True))\n",
    "display_stats(stats.groupby(\"parallel\").get_group(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moodify 3038860\n",
      "Shuttle 441873\n",
      "Diabetes 343664\n",
      "Pendigits 109920\n",
      "Annthyroid 43200\n",
      "Cardio 38451\n",
      "Ionosphere 11583\n",
      "Xaxis 6600\n",
      "Yaxis 6600\n",
      "Bisect 6600\n",
      "Bisec3D 6600\n",
      "Bisec6D 6600\n",
      "Breastw 6147\n",
      "Pima 6144\n",
      "Glass 1917\n",
      "Wine 1677\n",
      "Bimodal 800\n"
     ]
    }
   ],
   "source": [
    "names = [\n",
    "    \"Bimodal\",\n",
    "    \"Xaxis\",\n",
    "    \"Yaxis\",\n",
    "    \"Bisect\",\n",
    "    \"Bisec3D\",\n",
    "    \"Bisec6D\",\n",
    "    \"Annthyroid\",\n",
    "    \"Breastw\",\n",
    "    \"Cardio\",\n",
    "    \"Glass\",\n",
    "    \"Ionosphere\",\n",
    "    \"Pendigits\",\n",
    "    \"Pima\",\n",
    "    \"Shuttle\",\n",
    "    \"Wine\",\n",
    "    \"Diabetes\",\n",
    "    \"Moodify\",\n",
    "]\n",
    "\n",
    "sample_n = [\n",
    "    400,\n",
    "    1100,\n",
    "    1100,\n",
    "    1100,\n",
    "    1100,\n",
    "    1100,\n",
    "    7200,\n",
    "    683,\n",
    "    1831,\n",
    "    213,\n",
    "    351,\n",
    "    6870,\n",
    "    768,\n",
    "    49097,\n",
    "    129,\n",
    "    85916,\n",
    "    276260,\n",
    "]\n",
    "\n",
    "feat_n = [\n",
    "    2,\n",
    "    6,\n",
    "    6,\n",
    "    6,\n",
    "    6,\n",
    "    6,\n",
    "    6,\n",
    "    9,\n",
    "    21,\n",
    "    9,\n",
    "    33,\n",
    "    16,\n",
    "    8,\n",
    "    9,\n",
    "    13,\n",
    "    4,\n",
    "    11,\n",
    "]\n",
    "\n",
    "size = [(n, s*f) for n, s, f in zip(names, sample_n, feat_n)]\n",
    "\n",
    "# order size with the second element\n",
    "size.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for n, s in size:\n",
    "    print(n, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'importances_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# display_stats(stats)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m display(stats)\n\u001b[0;32m---> 15\u001b[0m imps_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimportances_matrix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimps_mat.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, imps_mat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m imp_mat_ex_0 \u001b[38;5;241m=\u001b[39m imps_mat[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/pandas/core/indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/pandas/core/frame.py:4202\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4199\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[0;32m-> 4202\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4203\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4206\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4207\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4208\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/pandas/core/frame.py:4626\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4621\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[1;32m   4622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4623\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4624\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[0;32m-> 4626\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4627\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4629\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'importances_matrix'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from append_dir import append_dirname\n",
    "append_dirname('ExIFFI')\n",
    "\n",
    "from capri_code.process_results import load_stats, display_stats\n",
    "\n",
    "\n",
    "results_dirpath = \"../capri_code/results/npz/new/new\"\n",
    "\n",
    "stats = load_stats(results_dirpath)\n",
    "\n",
    "# display_stats(stats)\n",
    "display(stats)\n",
    "\n",
    "imps_mat = np.array(stats.loc[0, \"importances_matrix\"])\n",
    "\n",
    "print(\"imps_mat.shape\", imps_mat.shape)\n",
    "\n",
    "\n",
    "imp_mat_ex_0 = imps_mat[0]\n",
    "print(\"imp_mat_ex_0.shape\", imp_mat_ex_0.shape)\n",
    "\n",
    "# for i in range(len(imp_mat_ex_0)-1):\n",
    "#     print(imp_mat_ex_0[i] - imp_mat_ex_0[i+1])\n",
    "\n",
    "imp_mat_ex_1 = imps_mat[1]\n",
    "\n",
    "# for i in range(len(imp_mat_ex_1)):\n",
    "#     print(imp_mat_ex_1[i] - imp_mat_ex_0[i])\n",
    "\n",
    "# print(imps_mat[0] - imps_mat[1])\n",
    "# print(imps_mat[1] - imps_mat[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "(3, 1)\n",
      "output\n",
      " [[11.]\n",
      " [11.]\n",
      " [11.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return x+10\n",
    "\n",
    "a = np.ones((3))\n",
    "\n",
    "# add newaxis to a\n",
    "a = a[:, np.newaxis]\n",
    "\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "output = np.apply_along_axis(func, 1, a)\n",
    "\n",
    "print(\"output\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-01-29 14:52:25.715026')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# current datetime\n",
    "import datetime\n",
    "\n",
    "# datetime compatible with pandas dataframe rows\n",
    "import pandas as pd\n",
    "datetime_row_pandas = pd.Timestamp.now()\n",
    "\n",
    "datetime_row_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/container/job2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../../container/job2/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Parallel python script:\n",
      "############################################################\n",
      "TESTING PARALLEL ExIFFI\n",
      "############################################################\n",
      "TEST PARAMETERS:\n",
      "Number of runs: 1\n",
      "Number of trees: 100\n",
      "Number of cores: fit 8, importance 8, anomaly 8\n",
      "Seed: 120\n",
      "Parallel: True\n",
      "############################################################\n",
      "dataset_names ['wine']\n",
      "############################################################\n",
      "DATASET: wine\n",
      "############################################################\n",
      "Experiment:   0%|                                         | 0/1 [00:00<?, ?it/s]Execution 1\n",
      "Set up Extended_DIFFI_parallel\n",
      "Finished setting up Extended_DIFFI_parallel\n",
      "Call compute_imps\n",
      "shape of X_train: (119, 13)\n",
      "shape of X_test: (129, 13)\n",
      "\n",
      "Fit & Importances:   0%|                                 | 0/10 [00:00<?, ?it/s]\u001b[AStart fit\n",
      "End fit\n",
      "Start Global Importance\n",
      "Start computing Anomaly Score\n",
      "End computing Anomaly Score\n",
      "Start computing Importances Score\n",
      "self.num_processes_importances: 8\n",
      "segment_size: 12\n",
      "Segments shapes: [(12,), (12,), (12,), (12,), (12,), (12,), (12,), (12,), (4,)]\n",
      "Stop computing Importances Score\n",
      "End Global Importance\n",
      "\n",
      "Fit & Importances:  10%|██▌                      | 1/10 [00:01<00:14,  1.59s/it]\u001b[AStart fit\n",
      "End fit\n",
      "Start Global Importance\n",
      "Start computing Anomaly Score\n",
      "End computing Anomaly Score\n",
      "Start computing Importances Score\n",
      "self.num_processes_importances: 8\n",
      "segment_size: 12\n",
      "Segments shapes: [(12,), (12,), (12,), (12,), (12,), (12,), (12,), (12,), (4,)]\n",
      "Stop computing Importances Score\n",
      "End Global Importance\n",
      "\n",
      "Fit & Importances:  20%|█████                    | 2/10 [00:02<00:11,  1.42s/it]\u001b[AStart fit\n",
      "End fit\n",
      "Start Global Importance\n",
      "Start computing Anomaly Score\n",
      "^C\n",
      "Process ForkPoolWorker-62:\n",
      "Process ForkPoolWorker-61:\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-58:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-64:\n",
      "Process ForkPoolWorker-63:\n",
      "Process ForkPoolWorker-57:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 345, in path\n",
      "    if val:\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 343, in path\n",
      "    while s is not None:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 344, in path\n",
      "    val = x.dot(n)-s>0\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 344, in path\n",
      "    val = x.dot(n)-s>0\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in segment_sum\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 77, in <listcomp>\n",
      "    part_sum = np.sum([tree.compute_paths(X) for tree in segment], axis=0)\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 363, in compute_paths\n",
      "    return np.apply_along_axis(path, 1, X)\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/models/Extended_IF.py\", line 344, in path\n",
      "    val = x.dot(n)-s>0\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/davidefrizzo/anaconda3/envs/hpc/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! ./exec_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'subprocess' has no attribute 'STDERR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Your Python script code here\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Execute the time command and capture the output\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m time_output \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./exec_parallel.sh\u001b[39m\u001b[38;5;124m\"\u001b[39m], stderr\u001b[38;5;241m=\u001b[39m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDERR\u001b[49m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Save the time output to a file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_output_err.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'subprocess' has no attribute 'STDERR'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Your Python script code here\n",
    "\n",
    "# Execute the time command and capture the output\n",
    "time_output = subprocess.check_output([\"./exec_parallel.sh\"], tsderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "# Save the time output to a file\n",
    "with open(\"time_output_err.txt\", \"w\") as file:\n",
    "    file.write(time_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['real', '0m13.487s'], ['user', '0m52.816s'], ['sys', '0m7.766s']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.split('\\t') for i in time_output.split(\"\\n\")[-4:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/capri_code'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../capri_code/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Fit & Importances:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Fit & Importances: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\u001b[A\n",
      "Experiment: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "TESTING PARALLEL ExIFFI\n",
      "############################################################\n",
      "TEST PARAMETERS:\n",
      "Number of runs: 1\n",
      "Number of trees: 300\n",
      "Number of cores: fit 12, importance 12, anomaly 12\n",
      "Seed: 123\n",
      "Parallel: True\n",
      "############################################################\n",
      "dataset_names ['wine']\n",
      "############################################################\n",
      "DATASET: wine\n",
      "############################################################\n",
      "Execution 1\n",
      "Set up Extended_DIFFI_parallel\n",
      "Finished setting up Extended_DIFFI_parallel\n",
      "Call compute_imps\n",
      "shape of X_train: (119, 13)\n",
      "shape of X_test: (129, 13)\n",
      "Start fit\n",
      "End fit\n",
      "Start Global Importance\n",
      "Start computing Anomaly Score\n",
      "End computing Anomaly Score\n",
      "Start computing Importances Score\n",
      "self.num_processes_importances: 12\n",
      "segment_size: 25\n",
      "Segments shapes: [(25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,)]\n",
      "Stop computing Importances Score\n",
      "End Global Importance\n",
      "End call compute_imps\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18.24user 2.70system 0:05.03elapsed 416%CPU (0avgtext+0avgdata 369980maxresident)k\n",
      "0inputs+16outputs (2major+321682minor)pagefaults 0swaps\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Your shell command as a string\n",
    "shell_command = 'time python test_parallel.py --n_runs 1 --savedir ./results/npz/new  --n_trees 300  --dataset_names wine --n_cores 12 --seed 123 --n_runs_imps 1'\n",
    "\n",
    "# Execute the command and capture the output\n",
    "output = subprocess.check_output(shell_command, shell=True, text=True)\n",
    "\n",
    "# Print or use the captured output as needed\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"############################################################\\nTESTING PARALLEL ExIFFI\\n############################################################\\nTEST PARAMETERS:\\nNumber of runs: 1\\nNumber of trees: 300\\nNumber of cores: fit 12, importance 12, anomaly 12\\nSeed: 123\\nParallel: True\\n############################################################\\ndataset_names ['wine']\\n############################################################\\nDATASET: wine\\n############################################################\\nExecution 1\\nSet up Extended_DIFFI_parallel\\nFinished setting up Extended_DIFFI_parallel\\nCall compute_imps\\nshape of X_train: (119, 13)\\nshape of X_test: (129, 13)\\nStart fit\\nEnd fit\\nStart Global Importance\\nStart computing Anomaly Score\\nEnd computing Anomaly Score\\nStart computing Importances Score\\nself.num_processes_importances: 12\\nsegment_size: 25\\nSegments shapes: [(25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,), (25,)]\\nStop computing Importances Score\\nEnd Global Importance\\nEnd call compute_imps\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davidefrizzo/Desktop/PHD/PHD COURSES/Parallel Computing HPC/HPC-Project-AD/ExIFFI/capri_code/results/npz/new'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "os.chdir('../capri_code/results/npz/new/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29-01-2024_14-40-58_annthyroid_test_stat_parallel.npz', '29-01-2024_16-59-18_wine_test_stat_parallel.npz', '29-01-2024_14-12-35_wine_test_stat_parallel.npz', '29-01-2024_17-02-05_wine_test_stat_parallel.npz', '29-01-2024_12-51-07_cardio_test_stat_parallel.npz', '29-01-2024_19-17-38_test_stat_parallel_wine.npz', '29-01-2024_14-14-24_wine_test_stat_parallel.npz', '29-01-2024_16-59-47_wine_test_stat_parallel.npz', '29-01-2024_18-21-27_wine_test_stat_parallel.npz', '29-01-2024_18-22-40_wine_test_stat_parallel.npz', '29-01-2024_14-56-08_wine_test_stat_parallel.npz', '29-01-2024_18-10-56_wine_test_stat_parallel.npz', '29-01-2024_19-14-07_wine_test_stat_parallel.npz', '29-01-2024_14-13-43_wine_test_stat_parallel.npz', '29-01-2024_12-47-38_wine_test_stat_parallel.npz', '29-01-2024_19-15-44_test_stat_parallel_wine.npz', '29-01-2024_18-16-09_wine_test_stat_parallel.npz', '29-01-2024_14-07-57_wine_test_stat_parallel.npz', '29-01-2024_14-31-29_wine_test_stat_parallel.npz', '29-01-2024_16-49-37_wine_test_stat_parallel.npz', '29-01-2024_14-11-27_wine_test_stat_parallel.npz', '29-01-2024_18-23-34_wine_test_stat_parallel.npz', '29-01-2024_12-48-59_wine_test_stat_parallel.npz', '29-01-2024_12-49-23_breastw_test_stat_parallel.npz', '29-01-2024_18-12-21_wine_test_stat_parallel.npz', '29-01-2024_12-47-58_wine_test_stat_parallel.npz']\n"
     ]
    }
   ],
   "source": [
    "search_word = \"29-01-2024\"\n",
    "pattern = f\"*{search_word}*\"\n",
    "\n",
    "matching_files = glob(pattern)\n",
    "print(matching_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=np.load('30-01-2024_10-07-13_test_stat_parallel_wine.npz',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'execution_time_stat is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexecution_time_stat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hpc/lib/python3.10/site-packages/numpy/lib/npyio.py:260\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'execution_time_stat is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "stats['execution_time_stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
