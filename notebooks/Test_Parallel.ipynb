{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from append_dir import append_dirname\n",
    "append_dirname('ExIFFI')\n",
    "from utils.utils import partition_data\n",
    "from utils.feature_selection import *\n",
    "#from plot import *\n",
    "#from simulation_setup import *\n",
    "from models import *\n",
    "from models.Extended_IF import *\n",
    "from models.Extended_DIFFI_parallel import *\n",
    "from models.Extended_DIFFI_original import *\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os\n",
    "import pickle \n",
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.getcwd()\n",
    "path=os.path.dirname(path)\n",
    "path=os.path.join(path,'data')\n",
    "mat_files=glob(os.path.join(path, '*.mat'))\n",
    "mat_file_names={os.path.basename(x).split('.')[0]:x for x in mat_files}\n",
    "csv_files=glob(os.path.join(path, '*.csv'))\n",
    "csv_file_names={os.path.basename(x).split('.')[0]:x for x in csv_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data=loadmat(mat_file_names[filename])\n",
    "    X,y=data['X'],data['y']\n",
    "    y=np.hstack(y)\n",
    "    return X,y \n",
    "\n",
    "def load_data_csv(filename):\n",
    "    data=pd.read_csv(csv_file_names[filename])\n",
    "    if 'Unnamed: 0' in data.columns:\n",
    "        data=data.drop(columns=['Unnamed: 0'])\n",
    "    X=data[data.columns[data.columns!='Target']]\n",
    "    y=data['Target']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_imps(model,X_train,X_test,n_runs,name,pwd,dim,f=6):\n",
    "\n",
    "    name='GFI_'+name\n",
    "\n",
    "    #X_test=np.r_[X_train,X_test]\n",
    "\n",
    "    imps=np.zeros(shape=(n_runs,X_train.shape[1]))\n",
    "    for i in tqdm(range(n_runs)):\n",
    "        model.fit(X_train)\n",
    "        imps[i,:]=model.Global_importance(X_test,calculate=True,overwrite=False,depth_based=False)\n",
    "\n",
    "    path = pwd + '/results/imp/imp_score_' + name + '.pkl'\n",
    "    with open(path, 'wb') as fl:\n",
    "        pickle.dump(imps,fl)\n",
    "\n",
    "    #Take the mean feature importance scores over the different runs for the Feature Importance Plot\n",
    "    #and put it in decreasing order of importance\n",
    "    mean_imp=np.mean(imps,axis=0)\n",
    "    std_imp=np.std(imps,axis=0)\n",
    "    mean_imp_val=np.sort(mean_imp)\n",
    "    feat_order=mean_imp.argsort()\n",
    "\n",
    "    plt_data={'Importances': mean_imp_val,\n",
    "              'feat_order': feat_order,\n",
    "              'std': std_imp[mean_imp.argsort()]}\n",
    "\n",
    "    path = pwd + '/results/plt_data/plt_data_' + name + '.pkl'\n",
    "    with open(path, 'wb') as fl:\n",
    "        pickle.dump(plt_data,fl)\n",
    "\n",
    "    return imps,plt_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129, 13), (129,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='wine'\n",
    "X,y=load_data(name)\n",
    "X_train,X_test=partition_data(X,y)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119, 13), (10, 13))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import time\n",
    "# scaler=StandardScaler()\n",
    "# X_train=scaler.fit_transform(X_train)\n",
    "# X_test=scaler.transform(X_test)\n",
    "# y_train=np.zeros(X_train.shape[0])\n",
    "# y_test=np.ones(X_test.shape[0])\n",
    "# y=np.concatenate([y_train,y_test])\n",
    "# X_test=np.r_[X_train,X_test]\n",
    "# scaler2=StandardScaler()\n",
    "# X=scaler2.fit_transform(X)\n",
    "# EDIFFI=Extended_DIFFI_original(300,max_depth=100,subsample_size=256,plus=1)\n",
    "# dim=X.shape[1]\n",
    "# pwd=os.path.dirname(os.getcwd())\n",
    "# start=time.time()\n",
    "# imps,plt_data=compute_imps(EDIFFI,X,X,10,name,pwd,dim,f=6)\n",
    "# end=time.time()\n",
    "# print(f'Elapsed time: {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:59<00:00,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 59.13217067718506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_train=np.zeros(X_train.shape[0])\n",
    "y_test=np.ones(X_test.shape[0])\n",
    "y=np.concatenate([y_train,y_test])\n",
    "X_test=np.r_[X_train,X_test]\n",
    "scaler2=StandardScaler()\n",
    "X=scaler2.fit_transform(X)\n",
    "EDIFFI=Extended_DIFFI_parallel(300,max_depth=100,subsample_size=256,plus=1)\n",
    "EDIFFI.set_num_processes(8)\n",
    "\n",
    "dim=X.shape[1]\n",
    "pwd=os.path.dirname(os.getcwd())\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "imps,plt_data=compute_imps(EDIFFI,X,X,10,name,pwd,dim,f=6)\n",
    "end=time.time()\n",
    "\n",
    "print(f'Elapsed time: {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((351, 33), (351,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='ionosphere'\n",
    "X,y=load_data(name)\n",
    "X_train,X_test=partition_data(X,y)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:54<00:00, 17.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 174.5880789756775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_train=np.zeros(X_train.shape[0])\n",
    "y_test=np.ones(X_test.shape[0])\n",
    "y=np.concatenate([y_train,y_test])\n",
    "X_test=np.r_[X_train,X_test]\n",
    "scaler2=StandardScaler()\n",
    "X=scaler2.fit_transform(X)\n",
    "EDIFFI=Extended_DIFFI_original(300,max_depth=100,subsample_size=256,plus=1)\n",
    "dim=X.shape[1]\n",
    "pwd=os.path.dirname(os.getcwd())\n",
    "start=time.time()\n",
    "imps,plt_data=compute_imps(EDIFFI,X,X,10,name,pwd,dim,f=6)\n",
    "end=time.time()\n",
    "print(f'Elapsed time: {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel ExIFFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:40<00:00, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 160.04758954048157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_train=np.zeros(X_train.shape[0])\n",
    "y_test=np.ones(X_test.shape[0])\n",
    "y=np.concatenate([y_train,y_test])\n",
    "X_test=np.r_[X_train,X_test]\n",
    "scaler2=StandardScaler()\n",
    "X=scaler2.fit_transform(X)\n",
    "EDIFFI=Extended_DIFFI_parallel(300,max_depth=100,subsample_size=256,plus=1)\n",
    "EDIFFI.set_num_processes(12)\n",
    "\n",
    "dim=X.shape[1]\n",
    "pwd=os.path.dirname(os.getcwd())\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "imps,plt_data=compute_imps(EDIFFI,X,X,10,name,pwd,dim,f=6)\n",
    "end=time.time()\n",
    "\n",
    "print(f'Elapsed time: {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Ionosphere\n",
    "\n",
    "Serial -> 174.5880789756775\n",
    "\n",
    "8 threads\n",
    "\n",
    "Parallel -> 147.8202040195465\n",
    "\n",
    "12 threads\n",
    "\n",
    "Parallel -> 137.81197714805603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "y_train=np.zeros(X_train.shape[0])\n",
    "y_test=np.ones(X_test.shape[0])\n",
    "y=np.concatenate([y_train,y_test])\n",
    "X_test=np.r_[X_train,X_test]\n",
    "scaler2=StandardScaler()\n",
    "X=scaler2.fit_transform(X)\n",
    "EDIFFI=Extended_DIFFI_parallel(300,max_depth=100,subsample_size=256,plus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDIFFI.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 4), (100000,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=load_data_csv('diabetes')\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
